# 1. 导数和牛顿迭代法

**导数** 全称 **导函数** ，过曲线上一点作切线，该切线的斜率就是导数在该点的值。  

由此，可得直接写出曲线上每一个点的切线方程：  

![$$y = f(x_0) + f'(x_0)(x - x_0) $$](https://raw.githubusercontent.com/chenBingX/img/master/机器学习相关/TangentEquation(切线方程).png)

这是这个公式的变形过程：  

假设 y = kx + b 为点 x0 处的切线函数，则有     

![$$ \frac{y - f(x_0)}{x - x0} = k = f'(x_0)  $$  ](https://raw.githubusercontent.com/chenBingX/img/master/机器学习相关/SlopeEquation(斜率方程).png)

稍加变换就变成上面的公式了。  

此时，令 y = 0，则可得到，  

![$$ x_1 = x_0 - \frac{f(x_0)}{f'(x_0)} $$  ](https://raw.githubusercontent.com/chenBingX/img/master/机器学习相关/x1方程.png)

上述 x1 是和 x0 紧密相邻的取值。  

如果推广开来可得到，  

![$$ x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)} $$  ](https://raw.githubusercontent.com/chenBingX/img/master/机器学习相关/x1推广方程.png) 

经过不断的迭代，x就越来越接近于函数的解了。

# 2. 复合函数求导
## 2.1 连乘型 函数求导

![$$ [g(x)f(x)]'= g'(x)f(x) + g(x)f'(x) $$ ](https://raw.githubusercontent.com/chenBingX/img/master/机器学习相关/ContinuousDerivation(连续型求导).png) 

## 2.2 嵌套型 函数求导

![$$ [g(f(x))]' = g'(x)f'(x) $$](https://raw.githubusercontent.com/chenBingX/img/master/机器学习相关/NestedDerivation(嵌套型求导).png)







